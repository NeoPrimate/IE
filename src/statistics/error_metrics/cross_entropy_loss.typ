== Cross-Entropy Loss (Log Loss)

Binary and multi-class classification

$
"Log Loss" = - 1 / n sum_(i=1)^n [y_i log(hat(y)_i) + (1 - y_i) log(1 - hat(y)_i)]
$